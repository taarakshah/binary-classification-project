---
title: "STAT 4052 Final Project"
author: "Taarak Shah"
date: "11/20/2019"
output: pdf_document
---

```{r}
#misc
library(class)
library(caret)
library(MASS)

#model selection
library(leaps)
#ROC / AUC
library(ROCR)
#trees
library(tree)
library(DAAG)
library(randomForest)
library(gbm)
```

# Mean imputed version (basic)

```{r}
bikes = read.table("data/bikes29.txt", header=TRUE)

# create Profit variable based on bike sharing
bikes$Profit = ifelse(bikes$N_bikes >= 20000, 1, 0)

# impute with the mean for continuous vars
# bikes$N_bikes[is.na(bikes$N_bikes)] = mean(bikes$N_bikes, na.rm = TRUE)
# don't impute N_bikes, it affects how many Profit
bikes$humidity[is.na(bikes$humidity)] = mean(bikes$humidity, na.rm = TRUE)
# remove rows with missing categorical vars (holiday)
bikes = bikes[complete.cases(bikes), ]

# changing to factors w/ categorical levels
bikes$Profit = as.factor(bikes$Profit)
bikes$holiday = as.factor(bikes$holiday)
bikes$weekend = as.factor(bikes$weekend)
bikes$season = as.factor(bikes$season)

bikes
```

### Split test and train

```{r}
set.seed(4052)
n = length(bikes[,1])
index = sample(seq(1:n), 0.7*n)
train = bikes[index,]
test = bikes[-index,]
```

### Logistic regression

```{r}
bin.glm = glm(Profit ~ temperature + feels_like + humidity + wind_speed + holiday + weekend + season, data=train, family="binomial")
summary(bin.glm)
```

```{r}
# best subset
(bss.reg.sum = summary(regsubsets(Profit ~ temperature + feels_like + humidity + wind_speed + holiday + weekend + season, data=train)))
which.max(bss.reg.sum$adjr2)
```

By best subset selection, the best logistic regression model is the one with all covariates except \texttt{season}. This model is fitted below:

```{r}
bin.glm2 = glm(Profit ~ temperature + feels_like + humidity + wind_speed + holiday + weekend, data=train, family="binomial")
summary(bin.glm2)
```

Next, predict on test data.

```{r}
pred.glm = predict.glm(bin.glm2, newdata = test, type="response")
pred.glm.class = ifelse(pred.glm > 0.5, 1, 0)
glm.ER = sum(pred.glm.class != test$Profit) / length(test$Profit)
glm.ER

table.glm = table(test$Profit, pred.glm.class)
table.glm
```

Next, construct ROC/AUC for logistic regression.

```{r}
# ROC and AUC for log reg
pred.glm2 = prediction(pred.glm, test$Profit)
perf.glm = performance(pred.glm2, "tpr", "fpr")
AUC.glm = performance(pred.glm2, "auc")@y.values[[1]]
plot(perf.glm, colorize=TRUE, main = "Logistic ROC curve")
AUC.glm
```

```{r}
# deviance testing
pchisq(bin.glm2$deviance, bin.glm2$df.residual, lower.tail = FALSE)
```

$H_0: l_\text{saturated} = l_\text{fitted}$

$H_a: l_\text{saturated} \neq l_\text{fitted}$

Fail to reject $H_0$, so then the fitted model is as good as the saturated model.

### KNN

Why to not use LDA/QDA: Can't assume Gaussian, since we have categorical predictors. Logistic will outperform LDA
KNN > LDA when decision boundary is not linear, since KNN nonparametric. Only choice is to use KNN.

First, choose subset of available predictors.

```{r}
x.train = matrix(c(train$temperature, train$feels_like, train$humidity, train$wind_speed, train$holiday, train$weekend, train$season), ncol=7)
x.test = matrix(c(test$temperature, test$feels_like, test$humidity, test$wind_speed, test$holiday, test$weekend, test$season), ncol=7)
```

Fit knn with various k values. Using cross-validation, k=7 is best.

```{r}
#knn k=3
set.seed(4052)
knn3 = knn(x.train, x.test, cl = train$Profit, k = 3, prob = TRUE, use.all = FALSE)
knn3.ER = sum(knn3 != test$Profit) / length(test$Profit)
knn3.ER

#knn k=5
set.seed(4052)
knn5 = knn(x.train, x.test, cl = train$Profit, k = 5, prob = TRUE, use.all = FALSE)
knn5.ER = sum(knn5 != test$Profit) / length(test$Profit)
knn5.ER

#knn k=7
set.seed(4052)
knn7 = knn(x.train, x.test, cl = train$Profit, k = 7, prob = TRUE, use.all = FALSE)
knn7.ER = sum(knn7 != test$Profit) / length(test$Profit)
knn7.ER

#knn k=9
set.seed(4052)
knn9 = knn(x.train, x.test, cl = train$Profit, k = 9, prob = TRUE, use.all = FALSE)
knn9.ER = sum(knn9 != test$Profit) / length(test$Profit)
knn9.ER

#knn k=11
set.seed(4052)
knn11 = knn(x.train, x.test, cl = train$Profit, k = 11, prob = TRUE, use.all = FALSE)
knn11.ER = sum(knn11 != test$Profit) / length(test$Profit)
knn11.ER

#knn k=13
set.seed(4052)
knn13 = knn(x.train, x.test, cl = train$Profit, k = 13, prob = TRUE, use.all = FALSE)
knn13.ER = sum(knn13 != test$Profit) / length(test$Profit)
knn13.ER

# CV for knn
set.seed(4052)
ctrl = trainControl(method = "repeatedcv", repeats = 5)
knnFit = train(Profit ~ temperature + feels_like + humidity + wind_speed + holiday + weekend + season, data = train, method = "knn", trControl = ctrl, preProcess = c("center", "scale"), tuneLength = 20)
knnFit
```


```{r}
# AUC / ROC for KNN
knn9prob = attr(knn9, "prob")
pred.knn = prediction(knn9prob, test$Profit)
perf.knn = performance(pred.knn, "tpr", "fpr")
AUC.knn = performance(pred.knn, "auc")@y.values[[1]]
plot(perf.knn, colorize=TRUE, main = "KNN ROC curve")
AUC.knn
```

### Decision tree, then choose RF

First construct decision tree:

```{r}
# decision tree
groot1 = tree(Profit ~ temperature + feels_like + humidity + wind_speed + holiday + weekend + season, data=train)
summary(groot1)
plot(groot1)
text(groot1, pretty = 0)
```

```{r}
# test error rate for unpruned tree
pred.tree = predict(groot1, newdata = test, type = "class")
table(test$Profit, pred.tree)
tree.ER1 = sum(pred.tree != test$Profit) / length(test$Profit)
tree.ER1

#AUC ROC for unpruned tree
unprune.auc = predict(groot1, newdata = test, type = "vector")
pred.unprune = prediction(unprune.auc[,2], test$Profit)
perf.unprune = performance(pred.unprune, "tpr", "fpr")
AUC.unprune = performance(pred.unprune, "auc")@y.values[[1]]
plot(perf.unprune, colorize=TRUE, main = "Unpruned ROC curve")
AUC.unprune
```

```{r}
# prune the tree
set.seed(4052)
groot2 <- cv.tree(groot1, FUN = prune.misclass)
plot(groot2$size, groot2$dev, type = "b")
groot3 = prune.misclass(groot1, best = 4)
plot(groot3)
text(groot3, pretty = 0)
```

```{r}
# test error rate for pruned tree
pred.tree2 = predict(groot3, newdata = test, type = "class")
table(test$Profit, pred.tree2)
tree.ER2 = sum(pred.tree2 != test$Profit) / length(test$Profit)
tree.ER2

#AUC ROC for pruned tree
prune.auc = predict(groot3, newdata = test, type = "vector")
pred.prune = prediction(prune.auc[,2], test$Profit)
perf.prune = performance(pred.prune, "tpr", "fpr")
AUC.prune = performance(pred.prune, "auc")@y.values[[1]]
plot(perf.prune, colorize=TRUE, main = "Pruned ROC curve")
AUC.prune
```

Then use RF algorithm. Bagging will not be that useful since it will lead to correlated trees. Good RF default for classification tree is $m = \sqrt p$.

```{r}
set.seed(4052)
#random forest
rf = randomForest(Profit ~ temperature + feels_like + humidity + wind_speed + holiday + weekend + season, data = train, mtry = 3, importance = TRUE)
pred.rf = predict(rf, newdata = test, type = "class")
table(test$Profit, pred.rf)
rf.ER = sum(pred.rf != test$Profit) / length(test$Profit)
rf.ER

importance(rf)
varImpPlot(rf)

#AUC ROC for randforest
pred.rf.auc = predict(rf, newdata = test, type="prob")
pred.rf2 = prediction(pred.rf.auc[,2], test$Profit)
perf.rf = performance(pred.rf2, "tpr", "fpr")
AUC.rf = performance(pred.rf2, "auc")@y.values[[1]]
plot(perf.rf, colorize=TRUE, main = "Random Forest ROC curve")
AUC.rf
```


Random forest has a lower test error rate than bagging, so we prefer to choose random forest over bagging. The difference in prediction performance is that we choose a lower number of predictors in random forest, whereas we choose all predictors to sample at splits for bagging. This lowers the variance and allows random forest to perform better.


\newpage

# Iterative regression imputation

With this method, we will impute $Nbikes$ and $humidity$.

```{r include = FALSE}
### Iterative regression imputation
set.seed(4052)

# imputation function
impute <- function(a, a.impute){ 
  ifelse(is.na(a), a.impute, a)
}

# simple random imputation
random.imp <- function(a){
  missing <- is.na(a)
  n.missing <- sum(missing)
  a.obs <- a[!missing]
  imputed <- a
  imputed[missing] <- sample(a.obs, n.missing, replace=TRUE) 
  return (imputed)
}

bikes = read.table("bikes29.txt", header=TRUE)
#create new category "missing"
bikes$holiday2 = bikes$holiday
bikes$holiday2[is.na(bikes$holiday2)] = c("missing")
#recode as factor
bikes$holiday = as.factor(bikes$holiday)
bikes$holiday2 = as.factor(bikes$holiday2)
bikes$weekend = as.factor(bikes$weekend)
bikes$season = as.factor(bikes$season)

Nbikes.imp <- random.imp(bikes$N_bikes) 
humidity.imp <- random.imp(bikes$humidity)

attach(bikes)
rep = 10
for (i in 1:rep){
  # impute N_bikes
  lm_1 = lm(N_bikes ~ temperature + feels_like + humidity.imp + wind_speed + holiday2 + weekend + season)
  data_temp = data.frame(temperature, feels_like, humidity.imp, wind_speed, holiday2, weekend, season)
  Nbikes.imp.1 <- impute(N_bikes, predict(lm_1, data_temp))
  lm_2 = lm(Nbikes.imp.1 ~ temperature + feels_like + humidity.imp + wind_speed + holiday2 + weekend + season)
  
  X = model.matrix(lm_2, data=data_temp)
  sigma.hat.square = sum(resid(lm_2)^2)/lm_2$df.residual*X%*%qr.solve(t(X)%*%X)%*%t(X)
  pred1 = mvrnorm(mu = predict(lm_2, data_temp), Sigma = sigma.hat.square)
  Nbikes.imp = impute(N_bikes, pred1)
  
  # impute humidity
  lm_3 = lm(humidity ~ Nbikes.imp + temperature + feels_like + wind_speed + holiday2 + weekend + season)
  data_temp = data.frame(Nbikes.imp, temperature, feels_like, wind_speed, holiday2, weekend, season)
  humidity.imp.1 <- impute(humidity, predict(lm_3, data_temp))
  lm_4 = lm(humidity.imp.1 ~ Nbikes.imp + temperature + feels_like + wind_speed + holiday2 + weekend + season)
  
  X = model.matrix(lm_4, data=data_temp)
  sigma.hat.square = sum(resid(lm_4)^2)/lm_4$df.residual*X%*%qr.solve(t(X)%*%X)%*%t(X)
  pred2 = mvrnorm(mu = predict(lm_4, data_temp), Sigma = sigma.hat.square)
  humidity.imp = impute(humidity, pred2)
}
```

```{r}
#adding iterative reg, proper coding
bikes$N_bikes = Nbikes.imp
bikes$humidity = humidity.imp

bikes$Profit = ifelse(bikes$N_bikes >= 20000, 1, 0)
bikes$Profit = as.factor(bikes$Profit)

bikes
```

### Split test and train

```{r}
set.seed(4052)
n = length(bikes[,1])
index = sample(seq(1:n), 0.7*n)
train = bikes[index,]
test = bikes[-index,]
```

### Logistic regression

```{r}
bin.glm = glm(Profit ~ temperature + feels_like + humidity + wind_speed + holiday2 + weekend + season, data=train, family="binomial")
summary(bin.glm)
```

```{r}
# best subset
(bss.reg.sum = summary(regsubsets(Profit ~ temperature + feels_like + humidity + wind_speed + holiday2 + weekend + season, data=train)))
which.max(bss.reg.sum$adjr2)
```

By best subset, the best logistic regression model is the one with all covariates except \texttt{temperature} and \texttt{season}. This model is fitted below:

```{r}
bin.glm2 = glm(Profit ~ feels_like + humidity + wind_speed + weekend, data=train, family="binomial")
summary(bin.glm2)
```

Next, predict on test data.

```{r}
pred.glm = predict.glm(bin.glm2, newdata = test, type="response")
pred.glm.class = ifelse(pred.glm > 0.5, 1, 0)
glm.ER = sum(pred.glm.class != test$Profit) / length(test$Profit)
glm.ER

table.glm = table(test$Profit, pred.glm.class)
table.glm
```

Next, construct ROC/AUC for logistic regression.

```{r}
# ROC and AUC for log reg
pred.glm2 = prediction(pred.glm, test$Profit)
perf.glm = performance(pred.glm2, "tpr", "fpr")
AUC.glm = performance(pred.glm2, "auc")@y.values[[1]]
plot(perf.glm, colorize=TRUE, main = "Logistic ROC curve")
AUC.glm
```

```{r}
# deviance testing
pchisq(bin.glm2$deviance, bin.glm2$df.residual, lower.tail = FALSE)
```

$H_0: l_\text{saturated} = l_\text{fitted}$

$H_a: l_\text{saturated} \neq l_\text{fitted}$

Fail to reject $H_0$, so then the fitted model is as good as the saturated model.

### KNN

First, choose subset of available predictors.

```{r}
x.train = matrix(c(train$temperature, train$feels_like, train$humidity, train$wind_speed, train$holiday2, train$weekend, train$season), ncol=7)
x.test = matrix(c(test$temperature, test$feels_like, test$humidity, test$wind_speed, test$holiday2, test$weekend, test$season), ncol=7)
```

Fit knn with various k values. Using cross-validation, k=9 is best.

```{r}
#knn k=3
set.seed(4052)
knn3 = knn(x.train, x.test, cl = train$Profit, k = 3, prob = TRUE, use.all = FALSE)
knn3.ER = sum(knn3 != test$Profit) / length(test$Profit)
knn3.ER

#knn k=5
set.seed(4052)
knn5 = knn(x.train, x.test, cl = train$Profit, k = 5, prob = TRUE, use.all = FALSE)
knn5.ER = sum(knn5 != test$Profit) / length(test$Profit)
knn5.ER

#knn k=7
set.seed(4052)
knn7 = knn(x.train, x.test, cl = train$Profit, k = 7, prob = TRUE, use.all = FALSE)
knn7.ER = sum(knn7 != test$Profit) / length(test$Profit)
knn7.ER

#knn k=9
set.seed(4052)
knn9 = knn(x.train, x.test, cl = train$Profit, k = 9, prob = TRUE, use.all = FALSE)
knn9.ER = sum(knn9 != test$Profit) / length(test$Profit)
knn9.ER

#knn k=11
set.seed(4052)
knn11 = knn(x.train, x.test, cl = train$Profit, k = 11, prob = TRUE, use.all = FALSE)
knn11.ER = sum(knn11 != test$Profit) / length(test$Profit)
knn11.ER

#knn k=13
set.seed(4052)
knn13 = knn(x.train, x.test, cl = train$Profit, k = 13, prob = TRUE, use.all = FALSE)
knn13.ER = sum(knn13 != test$Profit) / length(test$Profit)
knn13.ER

# CV for knn
set.seed(4052)
ctrl = trainControl(method = "repeatedcv", repeats = 5)
knnFit = train(Profit ~ temperature + feels_like + humidity + wind_speed + holiday2 + weekend + season, data = train, method = "knn", trControl = ctrl, preProcess = c("center", "scale"), tuneLength = 20)
knnFit
```


```{r}
# AUC / ROC for KNN
knn9prob = attr(knn9, "prob")
pred.knn = prediction(knn9prob, test$Profit)
perf.knn = performance(pred.knn, "tpr", "fpr")
AUC.knn = performance(pred.knn, "auc")@y.values[[1]]
plot(perf.knn, colorize=TRUE, main = "KNN ROC curve")
AUC.knn
```

### Decision tree, then RF

First construct decision tree:

```{r}
# decision tree
groot1 = tree(Profit ~ temperature + feels_like + humidity + wind_speed + holiday2 + weekend + season, data=train)
summary(groot1)
plot(groot1)
text(groot1, pretty = 0)
```

```{r}
# test error rate for unpruned tree
pred.tree = predict(groot1, newdata = test, type = "class")
table(test$Profit, pred.tree)
tree.ER1 = sum(pred.tree != test$Profit) / length(test$Profit)
tree.ER1
```

```{r}
# prune the tree
set.seed(4052)
groot2 <- cv.tree(groot1, FUN = prune.misclass)
plot(groot2$size, groot2$dev, type = "b")
groot3 = prune.misclass(groot1, best = 4)
plot(groot3)
text(groot3, pretty = 0)
```

```{r}
# test error rate for pruned tree
pred.tree2 = predict(groot3, newdata = test, type = "class")
table(test$Profit, pred.tree2)
tree.ER2 = sum(pred.tree2 != test$Profit) / length(test$Profit)
tree.ER2

#AUC ROC for pruned tree
prune.auc = predict(groot3, newdata = test, type = "vector")
pred.prune = prediction(prune.auc[,2], test$Profit)
perf.prune = performance(pred.prune, "tpr", "fpr")
AUC.prune = performance(pred.prune, "auc")@y.values[[1]]
plot(perf.prune, colorize=TRUE, main = "Pruned ROC curve")
AUC.prune
```

Then use RF algorithm. Bagging will not be that useful since it will lead to correlated trees. Good RF default for classification tree is $m = \sqrt p$.

```{r}
set.seed(4052)
#random forest
rf = randomForest(Profit ~ temperature + feels_like + humidity + wind_speed + holiday2 + weekend + season, data = train, mtry = 3, importance = TRUE)
pred.rf = predict(rf, newdata = test, type = "class")
table(test$Profit, pred.rf)
rf.ER = sum(pred.rf != test$Profit) / length(test$Profit)
rf.ER

importance(rf)
varImpPlot(rf)

#AUC ROC for randforest
pred.rf.auc = predict(rf, newdata = test, type="prob")
pred.rf2 = prediction(pred.rf.auc[,2], test$Profit)
perf.rf = performance(pred.rf2, "tpr", "fpr")
AUC.rf = performance(pred.rf2, "auc")@y.values[[1]]
plot(perf.rf, colorize=TRUE, main = "Random Forest ROC curve")
AUC.rf
```